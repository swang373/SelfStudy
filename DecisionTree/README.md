Decision tree learning algorithms are widely used for the tasks of classification and regression in a supervised context. They are so called because of their binary tree structure, where the root and internal nodes represent rules on how to categorize data and the leaves represent the final "conclusions" of the tree with respect to paths of branching decisions. They are popular because they are considered a "white-box" model in terms of interpretability, insensitive to differences in scale between different features, robust against collinearity, and non-parametric.

The learning algorithm hinges on how, at each node, the optimal manner in which to split the dataset is determined. For the root node, this means determining the optimal way to split the entire training dataset into two subsets. For the remaining internal nodes, this means finding the optimal way to split the subset of the training dataset that it encounters. This is an iterative and greedy procedure, as only the locally optimal split is considered at each step. The metric by which these splits are evaluated provides a loss function that can be optimized and thereby a method to grow the decision tree. Common metrics are the Gini impurity and information gain for classification tasks and the mean square error and Huber loss for regression tasks.

One of the most important hyperparameters for decision tree models are their depth, or the maximum distance between the root node and a leaf node. Intuitively, a decision tree requires a sufficient depth in order achieve the level of modelling flexibility required by the dataset for a task at hand. However, decision trees are also prone to overfitting for large values of depth, where the decisions made closest to the leaves may be capturing spurious fluctuations of the training data which reduce their ability to generalize. One approach to this bias-variance trade-off is through pruning of decision branches in deep trees, where nodes with an insignificant bearing on the predictive power of the model are removed.

Another approach to take advantage of the flexibility of decision trees while mitigating their tendency to overfit is the use of ensembling techniques. One example is through bootstrap aggregation, or bagging, where the training dataset is uniformly sampled with replacement to generate multiple new training samples. A decision tree model is learned for each of the generated training samples and their individual outputs are combined into a final result through a majority vote for classification tasks or averaging for regression tasks. Bagging is therefore a strategy to reduce the correlation between trees in the ensemble. Another example is boosting, where an ensemble of trees are grown by successively training trees and then combining their individual outputs in a weighted manner. Because the weights of the training examples are adjusted each time after a tree has been trained by upweighting incorrectly classified examples and downweighting correctly classified examples, each subsequent tree focuses on the examples that previous trees found difficult.

A random forest is also an ensemble of decision trees which are grown using bagging, but further randomness is incorporated into the algorithm by modifying the training such that each split in a tree is determined using a random subset of the input features. This strategy of "feature bagging" enables the ensemble to be more robust against cases where a small number of features provide most of the discriminative power in the dataset, causing even the trees in a bagged ensemble to become correlated.
